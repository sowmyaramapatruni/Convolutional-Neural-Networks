{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Prepare the data.\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from numpy import linalg as LA\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "images = np.load(\"./data/images.npy\")\n",
    "labels = np.load(\"./data/labels.npy\")\n",
    "\n",
    "images = np.reshape(images, (images.shape[0], images.shape[1] * images.shape[2]))\n",
    "\n",
    "images = images - images.mean()\n",
    "images = images/images.std() \n",
    "\n",
    "train_seqs = images[0:40000]\n",
    "val_seqs = images[40000:50000]\n",
    "\n",
    "train_labels = labels[0:40000]\n",
    "cv_labels = labels[40000:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH, NUM_CLASSES, NUM_OPT_STEPS, H = 26, 26, 5, 5000, 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "class TwoLayerNN(torch.nn.Module):\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(TwoLayerNN, self).__init__()\n",
    "        #self.Linear = torch.nn.Linear(D_in, D_out)\n",
    "        self.Linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.Linear2 = torch.nn.Linear(H, D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.Linear1(x)\n",
    "        h_relu = F.relu(h, inplace=False)\n",
    "        y_pred = self.Linear2(h_relu)\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TwoLayerNN(HEIGHT * WIDTH, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(batch_size):\n",
    "    model.train()\n",
    "    \n",
    "    i = np.random.choice(train_seqs.shape[0], size = batch_size, replace=False)\n",
    "    x = Variable(torch.from_numpy(train_seqs[i].astype(np.float32)))\n",
    "    y = Variable(torch.from_numpy(train_labels[i].astype(np.int)))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    count = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] == y_hat[i]:\n",
    "            count += 1\n",
    "    return count/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "#approx train accuracy() that extracts 1,000 random training\n",
    "#instances, creates a single batch with all of these inputs, computes integer predictions\n",
    "#for each example in the batch, and returns an accuracy by comparing these\n",
    "#predictions to the ground-truth labels.\n",
    "\n",
    "def approx_train_accuracy():\n",
    "    i = np.random.choice(train_seqs.shape[0], size = 1000, replace=False)\n",
    "    x = Variable(torch.from_numpy(train_seqs[i].astype(np.float32)))\n",
    "    y = train_labels[i].astype(np.int)\n",
    "    \n",
    "    output = model(x)\n",
    "    y_hat = np.argmax(output.data.numpy(), axis =1)\n",
    "    acc = accuracy(y,y_hat)\n",
    "    return acc\n",
    "\n",
    "\n",
    "#val accuracy() that creates a single batch with all validation\n",
    "#examples, computes integer predictions for each example in the batch, and returns\n",
    "#an accuracy by comparing these predictions to the ground-truth labels.\n",
    "\n",
    "def val_accuracy():\n",
    "    i = np.random.choice(val_seqs.shape[0], size = 1000, replace=False)\n",
    "    x = Variable(torch.from_numpy(val_seqs[i].astype(np.float32)))\n",
    "    y = cv_labels[i].astype(np.int) \n",
    "    \n",
    "    output = model(x)\n",
    "    y_hat = np.argmax(output.data.numpy(), axis =1)\n",
    "    acc = accuracy(y,y_hat)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_accs, val_accs = [], []\n",
    "batch_size = 1\n",
    "for i in range(5000):\n",
    "    l = train(batch_size)\n",
    "    if i % 100 == 0:\n",
    "        train_accs.append(approx_train_accuracy())\n",
    "        val_accs.append(val_accuracy())\n",
    "        print(\"%6d %5.2f %5.2f\" % (i, train_accs[-1], val_accs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "t = np.arange(0,len(train_accs),1)\n",
    "\n",
    "s = train_accs\n",
    "k = val_accs\n",
    "print(\"max_train accuracy: \", max(train_accs))\n",
    "print(\"max_val accuracy: \", max(val_accs))\n",
    "plt.figure(figsize=(8,8), dpi = 80)\n",
    "plt.plot(t, s, t, k)\n",
    "\n",
    "plt.xlabel('number of iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Training/validation accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in model.children():\n",
    "    m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_accs, val_accs = [], []\n",
    "batch_size = 10\n",
    "for i in range(5000):\n",
    "    l = train(batch_size)\n",
    "    if i % 100 == 0:\n",
    "        train_accs.append(approx_train_accuracy())\n",
    "        val_accs.append(val_accuracy())\n",
    "        print(\"%6d %5.2f %5.2f\" % (i, train_accs[-1], val_accs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "t = np.arange(0,len(train_accs),1)\n",
    "\n",
    "s = train_accs\n",
    "k = val_accs\n",
    "print(\"max_train accuracy: \", max(train_accs))\n",
    "print(\"max_val accuracy: \", max(val_accs))\n",
    "plt.figure(figsize=(8,8), dpi = 80)\n",
    "plt.plot(t, s, t, k)\n",
    "\n",
    "plt.xlabel('number of iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Training/validation accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in model.children():\n",
    "    m.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.0001)\n",
    "\n",
    "train_accs, val_accs = [], []\n",
    "batch_size = 500\n",
    "for i in range(10000):\n",
    "    l = train(batch_size)\n",
    "    if i % 100 == 0:\n",
    "        train_accs.append(approx_train_accuracy())\n",
    "        val_accs.append(val_accuracy())\n",
    "        print(\"%6d %5.2f %5.2f\" % (i, train_accs[-1], val_accs[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "t = np.arange(0,len(train_accs),1)\n",
    "\n",
    "s = train_accs\n",
    "k = val_accs\n",
    "print(\"max_train accuracy: \", max(train_accs))\n",
    "print(\"max_val accuracy: \", max(val_accs))\n",
    "plt.figure(figsize=(8,8), dpi = 80)\n",
    "plt.plot(t, s, t, k)\n",
    "\n",
    "plt.xlabel('number of iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Training/validation accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Validation Accuracy:\n",
    "\n",
    "The best validation accuracy reached = 89% at,\n",
    "\n",
    "learning rate = 0.0001\n",
    "\n",
    "Optimizer = Adam\n",
    "\n",
    "Batch size = 500\n",
    "\n",
    "Number of optimization steps = 10000\n",
    "\n",
    "Time taken to complete : 1 minute\n",
    "\n",
    "The model clearly overfits here. we are able to reach 87% validation accuracy (at lr = 0.001, batch size = 20, Optimization steps = 5000), anything beyond this, the model clearly overfits with high training accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
